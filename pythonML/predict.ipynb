{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e412313b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-14 09:48:21.420663: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-14 09:48:21.420730: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-14 09:48:21.420764: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-14 09:48:21.430613: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# import constants\n",
    "# from datasets import load_dataset\n",
    "# from utils import clean, make_current_datetime_dir, compute_metrics, preprocess_data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import TrainingArguments, Trainer, logging\n",
    "\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9745fb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_DEVICE_ORDER: PCI_BUS_ID\n",
      "CUDA_VISIBLE_DEVICES: 5\n",
      "1.13.1+cu117\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "\n",
    "# CUDA_DEVICE_ORDER 및 CUDA_VISIBLE_DEVICES 환경 변수 확인\n",
    "cuda_order = os.getenv(\"CUDA_DEVICE_ORDER\")\n",
    "cuda_visible_devices = os.getenv(\"CUDA_VISIBLE_DEVICES\")\n",
    "\n",
    "print(\"CUDA_DEVICE_ORDER:\", cuda_order)\n",
    "print(\"CUDA_VISIBLE_DEVICES:\", cuda_visible_devices)\n",
    "\n",
    "print(torch.__version__)\n",
    "# device = \"cpu\"\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97a9091b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(54343, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = './temp/electra'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6cd23f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# TrainingArguments 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',  # 결과 및 임시 파일 저장 경로\n",
    "    do_train=False,  # 훈련 안 함\n",
    "    do_predict=True  # 예측 수행\n",
    ")\n",
    "\n",
    "# Trainer 객체 생성\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84d5a138",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KoelectraDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4e10a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base-v2022\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./tokenizer\")\n",
    "\n",
    "test_path = \"mydata/my_pred.csv\"\n",
    "test_data = pd.read_csv(test_path, sep=',')\n",
    "\n",
    "max_len = 64          # 문장의 길이 (평균 13정도)\n",
    "batch_size = 32\n",
    "num_epochs = 3\n",
    "log_interval = 500    # metrics 생성 시점\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42c006ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "디코딩 : [CLS] 유저0 : 원조가 진짜 생존 유튜버였고 그 유튜브 보면 관련 영상으로 짭이 뜨는데 제가 처음 그거 봤을 때 영상 속에서 중장비 캐터필러 자국을 발견해서 단박에 주작인지 눈치챘었음ㅋㅋㅋ 그리고 다른 짭들도 작업속도가 지나치게 빨라서 다 주작이구나 했는데 결국 현장 [SEP]\n",
      "디코딩 : [CLS] # # # [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터\n",
    "# ==> 토크나이징 + 패딩 : dim=32\n",
    "encoded_test = tokenizer(\n",
    "    test_data['text'].tolist(),\n",
    "    return_tensors='pt',\n",
    "    max_length=max_len,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "print('디코딩 :',tokenizer.decode(encoded_test[0].ids))\n",
    "print('디코딩 :',tokenizer.decode(encoded_test[-1].ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b22143a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2748402/548597468.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(672, 3) (672,)\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/course/en/chapter3/3?fw=pt#evaluation\n",
    "# 데이터셋 생성\n",
    "zero_labels = np.zeros(len(test_data), dtype=int)\n",
    "test_dataset = KoelectraDataset(encoded_test, zero_labels)\n",
    "# 예측하기\n",
    "predictions = trainer.predict(test_dataset)\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff3f53b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "probabilities = softmax(predictions.predictions, axis=1)\n",
    "predicted_labels = np.argmax(probabilities, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e167f480",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = test_data['text']  # 테스트 데이터셋에서 텍스트 열 추출\n",
    "actual_labels = test_data['label']  # 실제 레이블 열\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    \"text\": test_texts,\n",
    "    \"actual_label\": actual_labels,\n",
    "    \"predicted_label\": predicted_labels,\n",
    "    \"probability_0\": probabilities[:, 0],\n",
    "    \"probability_1\": probabilities[:, 1],\n",
    "    \"probability_2\": probabilities[:, 2]  # 클래스가 더 많다면 이를 확장\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95de8079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>probability_0</th>\n",
       "      <th>probability_1</th>\n",
       "      <th>probability_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>유저16: ㅋㅋㅋㅋㅋㅋㅋㅋ재밌노 고소한다 그러노 근송이 큰일났네</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.997925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>유저14: @털복이 솔직히 나이 어린 게 좀 티나긴 해...ㅋㅋ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>0.669407</td>\n",
       "      <td>0.328415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>유저28: @안근 송 나 병@인가봐.....</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.966252</td>\n",
       "      <td>0.004216</td>\n",
       "      <td>0.029531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>유저47: 그것들을 진짜라고 생각했으면 ㄹㅇ 그런 지능으로 어떻게 살아가노</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033828</td>\n",
       "      <td>0.018019</td>\n",
       "      <td>0.948153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>유저48: 하 병신의 나라답다. 주작이라고 밝혀지니까 너도나도 애초에 수상했데 ㅋㅋ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.959671</td>\n",
       "      <td>0.011670</td>\n",
       "      <td>0.028659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>유저7: @@xhahrbhtahdhhd 개꼬였네</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.011155</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.984708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>유저8: @@xhahrbhtahdhhd 누가 그 유튜버가 혼자 구석기-신석기~청동기...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.037407</td>\n",
       "      <td>0.013594</td>\n",
       "      <td>0.948999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>유저9: 이게 맞지. 애초에 그 사람은 생존 보단 원시의 기술을 재현하는 데에 의의...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.514852</td>\n",
       "      <td>0.009345</td>\n",
       "      <td>0.475802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>유저11: @@user-bn9tv2ds1i 애니프사</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.997485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>유저14: 원시기술은   불한번 붙이는데 n세월아 네월아 걸리는게 기술이지nn 걍 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007823</td>\n",
       "      <td>0.004795</td>\n",
       "      <td>0.987382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  actual_label  \\\n",
       "17                 유저16: ㅋㅋㅋㅋㅋㅋㅋㅋ재밌노 고소한다 그러노 근송이 큰일났네           1.0   \n",
       "18                 유저14: @털복이 솔직히 나이 어린 게 좀 티나긴 해...ㅋㅋ           2.0   \n",
       "32                            유저28: @안근 송 나 병@인가봐.....           2.0   \n",
       "52           유저47: 그것들을 진짜라고 생각했으면 ㄹㅇ 그런 지능으로 어떻게 살아가노           0.0   \n",
       "53   유저48: 하 병신의 나라답다. 주작이라고 밝혀지니까 너도나도 애초에 수상했데 ㅋㅋ...           2.0   \n",
       "..                                                 ...           ...   \n",
       "648                         유저7: @@xhahrbhtahdhhd 개꼬였네           0.0   \n",
       "649  유저8: @@xhahrbhtahdhhd 누가 그 유튜버가 혼자 구석기-신석기~청동기...           0.0   \n",
       "650  유저9: 이게 맞지. 애초에 그 사람은 생존 보단 원시의 기술을 재현하는 데에 의의...           2.0   \n",
       "652                       유저11: @@user-bn9tv2ds1i 애니프사           1.0   \n",
       "656  유저14: 원시기술은   불한번 붙이는데 n세월아 네월아 걸리는게 기술이지nn 걍 ...           0.0   \n",
       "\n",
       "     predicted_label  probability_0  probability_1  probability_2  \n",
       "17                 2       0.001301       0.000774       0.997925  \n",
       "18                 1       0.002178       0.669407       0.328415  \n",
       "32                 0       0.966252       0.004216       0.029531  \n",
       "52                 2       0.033828       0.018019       0.948153  \n",
       "53                 0       0.959671       0.011670       0.028659  \n",
       "..               ...            ...            ...            ...  \n",
       "648                2       0.011155       0.004136       0.984708  \n",
       "649                2       0.037407       0.013594       0.948999  \n",
       "650                0       0.514852       0.009345       0.475802  \n",
       "652                2       0.001591       0.000924       0.997485  \n",
       "656                2       0.007823       0.004795       0.987382  \n",
       "\n",
       "[95 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측이 틀린 경우만 보기\n",
    "incorrect_predictions = df_results[df_results['actual_label'] != df_results['predicted_label']]\n",
    "correct_predictions = df_results[df_results['actual_label'] == df_results['predicted_label']]\n",
    "# print(incorrect_predictions)\n",
    "incorrect_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87682b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8586\n"
     ]
    }
   ],
   "source": [
    "accuracy = len(correct_predictions) / len(test_data)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d4605e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>probability_0</th>\n",
       "      <th>probability_1</th>\n",
       "      <th>probability_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>유저14: @털복이 솔직히 나이 어린 게 좀 티나긴 해...ㅋㅋ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>0.669407</td>\n",
       "      <td>0.328415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>유저28: @안근 송 나 병@인가봐.....</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.966252</td>\n",
       "      <td>0.004216</td>\n",
       "      <td>0.029531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>유저48: 하 병신의 나라답다. 주작이라고 밝혀지니까 너도나도 애초에 수상했데 ㅋㅋ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.959671</td>\n",
       "      <td>0.011670</td>\n",
       "      <td>0.028659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>유저57: @@user-bo1zx8jb6q 넌 황현진빠는 무지성이니까</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008104</td>\n",
       "      <td>0.960363</td>\n",
       "      <td>0.031533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>유저75: 당연한거지n중장비로 하루 투자해서n사람이 한달동안ㅈ빠지게 해야하는일을n금...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.672207</td>\n",
       "      <td>0.009675</td>\n",
       "      <td>0.318118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>유저24: @@iple4445 문법 나치같이 한 것도 아니고 그냥 알려줘도 지랄이네...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.976921</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.021840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>유저28: 아이고ㅆㅂ 맞춤범 지적안하면 손가락이 부러지나?그토록 십선인척 하고 싶었...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.902007</td>\n",
       "      <td>0.006001</td>\n",
       "      <td>0.091992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>유저40: @@neongnyang 녕냥갱 먹고싶누</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.945557</td>\n",
       "      <td>0.043988</td>\n",
       "      <td>0.010455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>유저60: 다름아닌 그깟 맞춤법 하나 가지고 이렇게 싸우는 거냐 지금? 역시 사소한...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826851</td>\n",
       "      <td>0.062747</td>\n",
       "      <td>0.110402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>유저52: @@user-vq2rk8vs4f 네 그건 됐구여 왜 국립국어원에서 며칠이...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974608</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>0.023819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>유저73: @@user-lx4ux3nx2u nn국립국어원 : 항상 ‘며칠’로 적는다...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.704308</td>\n",
       "      <td>0.042755</td>\n",
       "      <td>0.252937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>유저97: 몇 일을 며칠로 바꾼 겁니다. 맞춤법은 수시로 바뀌어서 딱히 의미가 없어...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011596</td>\n",
       "      <td>0.556992</td>\n",
       "      <td>0.431412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>유저129: 며칠에서 ㄹ만옮기면 멸치됨ㅋㅋㅋ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004412</td>\n",
       "      <td>0.814474</td>\n",
       "      <td>0.181114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>유저135: 동남아는 뺴,, 니두 백인이 봤을땐 그냥 하챦은 동양인임</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003848</td>\n",
       "      <td>0.979979</td>\n",
       "      <td>0.016173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>유저142: 맨파워는 뭐노ㅋㅋ한남파워 뭐이런건가ㅋㅋn되게작겠노ㅋ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>0.661224</td>\n",
       "      <td>0.328418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>유저158: 에휴 버러지들마냥 그저 아는척하고 싶어서 안달났누 ㅋㅋㅋㅋ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.817087</td>\n",
       "      <td>0.106140</td>\n",
       "      <td>0.076773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>유저159: 나이가 몇겐대 저걸믿냐 ㅉㅉ 그림만 봐  생각은 너희랑 안 어울려</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.945808</td>\n",
       "      <td>0.051584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>유저164: 군필자라면 당연히 안믿는 영상..</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.658253</td>\n",
       "      <td>0.339719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>유저169: 주쟉 안밝혀졌으면 우와 대단하다 거렸을 놈들이 궁예짓하는거 ㅈㄴ 때리고...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.984925</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.013162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>유저3: @@SeongHooon 존나 당당하게 말해서 개 어이가 없네ㅋㅋㅋㅋㅋㅋㅋ ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.976422</td>\n",
       "      <td>0.002416</td>\n",
       "      <td>0.021162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>유저18: @@DD-oi1ur 주작이 뭔지 모름...?ㅋㅋㅋㅋ;;;;  국평오가 엊...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.649121</td>\n",
       "      <td>0.225906</td>\n",
       "      <td>0.124973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>유저12: @@user-vd5jm5ld5y 틀니력 치사량</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002109</td>\n",
       "      <td>0.989458</td>\n",
       "      <td>0.008433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>유저31: @@user-vd5jm5ld5y  이런사람 주위 있음 존나 피곤함  선입...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.954112</td>\n",
       "      <td>0.004175</td>\n",
       "      <td>0.041714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>유저33: @@user-vd5jm5ld5y P.T님의 실력과 기술에 대해서는 NGO...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.933774</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>0.063869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>유저43: 꼭 해보지도 보지도 않은 새끼들이 거대충 검색 몇번하고 무슨 시발 눈앞에...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994645</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>0.003787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>유저9: 이게 맞지. 애초에 그 사람은 생존 보단 원시의 기술을 재현하는 데에 의의...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.514852</td>\n",
       "      <td>0.009345</td>\n",
       "      <td>0.475802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  actual_label  \\\n",
       "18                 유저14: @털복이 솔직히 나이 어린 게 좀 티나긴 해...ㅋㅋ           2.0   \n",
       "32                            유저28: @안근 송 나 병@인가봐.....           2.0   \n",
       "53   유저48: 하 병신의 나라답다. 주작이라고 밝혀지니까 너도나도 애초에 수상했데 ㅋㅋ...           2.0   \n",
       "66              유저57: @@user-bo1zx8jb6q 넌 황현진빠는 무지성이니까           2.0   \n",
       "84   유저75: 당연한거지n중장비로 하루 투자해서n사람이 한달동안ㅈ빠지게 해야하는일을n금...           2.0   \n",
       "183  유저24: @@iple4445 문법 나치같이 한 것도 아니고 그냥 알려줘도 지랄이네...           2.0   \n",
       "187  유저28: 아이고ㅆㅂ 맞춤범 지적안하면 손가락이 부러지나?그토록 십선인척 하고 싶었...           2.0   \n",
       "199                        유저40: @@neongnyang 녕냥갱 먹고싶누           2.0   \n",
       "223  유저60: 다름아닌 그깟 맞춤법 하나 가지고 이렇게 싸우는 거냐 지금? 역시 사소한...           2.0   \n",
       "248  유저52: @@user-vq2rk8vs4f 네 그건 됐구여 왜 국립국어원에서 며칠이...           2.0   \n",
       "251  유저73: @@user-lx4ux3nx2u nn국립국어원 : 항상 ‘며칠’로 적는다...           2.0   \n",
       "280  유저97: 몇 일을 며칠로 바꾼 겁니다. 맞춤법은 수시로 바뀌어서 딱히 의미가 없어...           2.0   \n",
       "319                           유저129: 며칠에서 ㄹ만옮기면 멸치됨ㅋㅋㅋ           2.0   \n",
       "334             유저135: 동남아는 뺴,, 니두 백인이 봤을땐 그냥 하챦은 동양인임           2.0   \n",
       "342                유저142: 맨파워는 뭐노ㅋㅋ한남파워 뭐이런건가ㅋㅋn되게작겠노ㅋ           2.0   \n",
       "361            유저158: 에휴 버러지들마냥 그저 아는척하고 싶어서 안달났누 ㅋㅋㅋㅋ           2.0   \n",
       "362        유저159: 나이가 몇겐대 저걸믿냐 ㅉㅉ 그림만 봐  생각은 너희랑 안 어울려           2.0   \n",
       "369                          유저164: 군필자라면 당연히 안믿는 영상..           2.0   \n",
       "402  유저169: 주쟉 안밝혀졌으면 우와 대단하다 거렸을 놈들이 궁예짓하는거 ㅈㄴ 때리고...           2.0   \n",
       "416  유저3: @@SeongHooon 존나 당당하게 말해서 개 어이가 없네ㅋㅋㅋㅋㅋㅋㅋ ...           2.0   \n",
       "513  유저18: @@DD-oi1ur 주작이 뭔지 모름...?ㅋㅋㅋㅋ;;;;  국평오가 엊...           2.0   \n",
       "535                    유저12: @@user-vd5jm5ld5y 틀니력 치사량           2.0   \n",
       "557  유저31: @@user-vd5jm5ld5y  이런사람 주위 있음 존나 피곤함  선입...           2.0   \n",
       "559  유저33: @@user-vd5jm5ld5y P.T님의 실력과 기술에 대해서는 NGO...           2.0   \n",
       "573  유저43: 꼭 해보지도 보지도 않은 새끼들이 거대충 검색 몇번하고 무슨 시발 눈앞에...           2.0   \n",
       "650  유저9: 이게 맞지. 애초에 그 사람은 생존 보단 원시의 기술을 재현하는 데에 의의...           2.0   \n",
       "\n",
       "     predicted_label  probability_0  probability_1  probability_2  \n",
       "18                 1       0.002178       0.669407       0.328415  \n",
       "32                 0       0.966252       0.004216       0.029531  \n",
       "53                 0       0.959671       0.011670       0.028659  \n",
       "66                 1       0.008104       0.960363       0.031533  \n",
       "84                 0       0.672207       0.009675       0.318118  \n",
       "183                0       0.976921       0.001239       0.021840  \n",
       "187                0       0.902007       0.006001       0.091992  \n",
       "199                0       0.945557       0.043988       0.010455  \n",
       "223                0       0.826851       0.062747       0.110402  \n",
       "248                0       0.974608       0.001573       0.023819  \n",
       "251                0       0.704308       0.042755       0.252937  \n",
       "280                1       0.011596       0.556992       0.431412  \n",
       "319                1       0.004412       0.814474       0.181114  \n",
       "334                1       0.003848       0.979979       0.016173  \n",
       "342                1       0.010358       0.661224       0.328418  \n",
       "361                0       0.817087       0.106140       0.076773  \n",
       "362                1       0.002608       0.945808       0.051584  \n",
       "369                1       0.002029       0.658253       0.339719  \n",
       "402                0       0.984925       0.001912       0.013162  \n",
       "416                0       0.976422       0.002416       0.021162  \n",
       "513                0       0.649121       0.225906       0.124973  \n",
       "535                1       0.002109       0.989458       0.008433  \n",
       "557                0       0.954112       0.004175       0.041714  \n",
       "559                0       0.933774       0.002356       0.063869  \n",
       "573                0       0.994645       0.001568       0.003787  \n",
       "650                0       0.514852       0.009345       0.475802  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_predictions[incorrect_predictions['actual_label']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cb4e2e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>probability_0</th>\n",
       "      <th>probability_1</th>\n",
       "      <th>probability_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>유저16: ㅋㅋㅋㅋㅋㅋㅋㅋ재밌노 고소한다 그러노 근송이 큰일났네</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.997925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>유저47: 그것들을 진짜라고 생각했으면 ㄹㅇ 그런 지능으로 어떻게 살아가노</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033828</td>\n",
       "      <td>0.018019</td>\n",
       "      <td>0.948153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>유저84: 주작이든 아니든 크리에이터 본인이 영상만드는건데 뭔 범죄라도 저지른것마냥...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>0.997201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>유저93: 구라까네 몰랐으면서</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.074731</td>\n",
       "      <td>0.009342</td>\n",
       "      <td>0.915927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>유저93: @@ttulgi09 현장에서 일하는 사람말고는 다 알았다는 사람들은 개구...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.012768</td>\n",
       "      <td>0.004934</td>\n",
       "      <td>0.982297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>유저5: @@bearangry9075 억지국뽕</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002753</td>\n",
       "      <td>0.400347</td>\n",
       "      <td>0.596900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>유저7: @@xhahrbhtahdhhd 개꼬였네</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.011155</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.984708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>유저8: @@xhahrbhtahdhhd 누가 그 유튜버가 혼자 구석기-신석기~청동기...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.037407</td>\n",
       "      <td>0.013594</td>\n",
       "      <td>0.948999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>유저11: @@user-bn9tv2ds1i 애니프사</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.997485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>유저14: 원시기술은   불한번 붙이는데 n세월아 네월아 걸리는게 기술이지nn 걍 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007823</td>\n",
       "      <td>0.004795</td>\n",
       "      <td>0.987382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  actual_label  \\\n",
       "17                 유저16: ㅋㅋㅋㅋㅋㅋㅋㅋ재밌노 고소한다 그러노 근송이 큰일났네           1.0   \n",
       "52           유저47: 그것들을 진짜라고 생각했으면 ㄹㅇ 그런 지능으로 어떻게 살아가노           0.0   \n",
       "93   유저84: 주작이든 아니든 크리에이터 본인이 영상만드는건데 뭔 범죄라도 저지른것마냥...           1.0   \n",
       "102                                   유저93: 구라까네 몰랐으면서           0.0   \n",
       "104  유저93: @@ttulgi09 현장에서 일하는 사람말고는 다 알았다는 사람들은 개구...           0.0   \n",
       "..                                                 ...           ...   \n",
       "602                          유저5: @@bearangry9075 억지국뽕           1.0   \n",
       "648                         유저7: @@xhahrbhtahdhhd 개꼬였네           0.0   \n",
       "649  유저8: @@xhahrbhtahdhhd 누가 그 유튜버가 혼자 구석기-신석기~청동기...           0.0   \n",
       "652                       유저11: @@user-bn9tv2ds1i 애니프사           1.0   \n",
       "656  유저14: 원시기술은   불한번 붙이는데 n세월아 네월아 걸리는게 기술이지nn 걍 ...           0.0   \n",
       "\n",
       "     predicted_label  probability_0  probability_1  probability_2  \n",
       "17                 2       0.001301       0.000774       0.997925  \n",
       "52                 2       0.033828       0.018019       0.948153  \n",
       "93                 2       0.001906       0.000893       0.997201  \n",
       "102                2       0.074731       0.009342       0.915927  \n",
       "104                2       0.012768       0.004934       0.982297  \n",
       "..               ...            ...            ...            ...  \n",
       "602                2       0.002753       0.400347       0.596900  \n",
       "648                2       0.011155       0.004136       0.984708  \n",
       "649                2       0.037407       0.013594       0.948999  \n",
       "652                2       0.001591       0.000924       0.997485  \n",
       "656                2       0.007823       0.004795       0.987382  \n",
       "\n",
       "[61 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.set_option('display.max_rows', 100)\n",
    "\n",
    "incorrect_predictions[incorrect_predictions['predicted_label']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf43583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.save_pretrained('./tokenizer')\n",
    "# torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cbc838",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba5fbcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93007270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
